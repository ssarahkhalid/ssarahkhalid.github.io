<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>mettadology · on alignment</title>
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="512x512" href="../android-chrome-512x512.png">
    <link rel="apple-touch-icon" sizes="180x180" href="../android-chrome-512x512.png">
    <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,500;0,600;1,400;1,500&family=DM+Serif+Display:ital@0;1&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet">
    <style>
        :root {
            --ivory: #FFFEF9;
            --cream: #F5F1E8;
            --sand: #E8E0D0;
            --terracotta: #C4704F;
            --charcoal: #2D2D2D;
            --warm-gray: #6B6560;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Crimson Pro', Georgia, serif;
            background: var(--ivory);
            color: var(--charcoal);
            line-height: 1.75;
            font-size: 19px;
        }
        
        .container {
            max-width: 720px;
            margin: 0 auto;
            padding: 4rem 2rem;
        }
        
        header {
            margin-bottom: 4rem;
        }
        
        .nav-back {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.85rem;
            color: var(--warm-gray);
            text-decoration: none;
            display: inline-block;
            margin-bottom: 2rem;
        }
        
        .nav-back:hover {
            color: var(--terracotta);
        }
        
        h1 {
            font-family: 'DM Serif Display', Georgia, serif;
            font-size: 2.8rem;
            font-weight: 400;
            line-height: 1.2;
            margin-bottom: 0.5rem;
            color: var(--charcoal);
        }
        
        .subtitle {
            font-family: 'DM Serif Display', Georgia, serif;
            font-style: italic;
            font-size: 1.4rem;
            color: var(--terracotta);
            margin-bottom: 1.5rem;
        }
        
        .meta {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.85rem;
            color: var(--warm-gray);
        }
        
        .toc {
            margin: 2rem 0 3rem;
            padding: 1.5rem 2rem;
            background: var(--cream);
            border-radius: 4px;
        }
        
        .toc-title {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.75rem;
            color: var(--warm-gray);
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 1rem;
        }
        
        .toc ul {
            list-style: none;
            padding: 0;
        }
        
        .toc li {
            margin-bottom: 0.5rem;
        }
        
        .toc a {
            font-family: 'Crimson Pro', Georgia, serif;
            font-size: 1rem;
            color: var(--charcoal);
            text-decoration: none;
        }
        
        .toc a:hover {
            color: var(--terracotta);
        }
        
        .epigraph {
            margin: 3rem 0;
            padding: 2rem 0;
            border-top: 1px solid var(--sand);
            border-bottom: 1px solid var(--sand);
        }
        
        .epigraph blockquote {
            font-style: italic;
            font-size: 1.15rem;
            color: var(--warm-gray);
            margin-bottom: 0.75rem;
        }
        
        .epigraph cite {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.8rem;
            font-style: normal;
            color: var(--warm-gray);
        }
        
        h2 {
            font-family: 'DM Serif Display', Georgia, serif;
            font-size: 1.8rem;
            font-weight: 400;
            margin: 3rem 0 1.5rem;
            color: var(--charcoal);
        }
        
        h3 {
            font-family: 'Crimson Pro', Georgia, serif;
            font-size: 1.3rem;
            font-weight: 600;
            margin: 2.5rem 0 1rem;
            color: var(--terracotta);
        }
        
        p {
            margin-bottom: 1.5rem;
        }
        
        .opening-line {
            font-size: 1.25rem;
            line-height: 1.6;
        }
        
        a {
            color: var(--terracotta);
            text-decoration: underline;
            text-decoration-thickness: 1px;
            text-underline-offset: 2px;
        }
        
        a:hover {
            text-decoration-thickness: 2px;
        }
        
        .section-break {
            text-align: center;
            margin: 3rem 0;
            color: var(--sand);
            font-size: 1.2rem;
            letter-spacing: 0.5em;
        }
        
        .link-card {
            background: var(--cream);
            padding: 1.5rem 2rem;
            margin: 2rem 0;
            border-left: 3px solid var(--terracotta);
        }
        
        .link-card .link-meta {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.75rem;
            color: var(--warm-gray);
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.5rem;
        }
        
        .link-card .link-title {
            font-family: 'DM Serif Display', Georgia, serif;
            font-size: 1.15rem;
            margin-bottom: 0.5rem;
        }
        
        .link-card .link-title a {
            color: var(--charcoal);
        }
        
        .link-card p {
            font-size: 0.95rem;
            margin-bottom: 0;
        }
        
        blockquote {
            margin: 2rem 0;
            padding-left: 1.5rem;
            border-left: 2px solid var(--terracotta);
            font-style: italic;
            color: var(--warm-gray);
        }
        
        blockquote cite {
            display: block;
            margin-top: 0.5rem;
            font-style: normal;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.8rem;
        }
        
        .code-block {
            background: var(--charcoal);
            color: var(--cream);
            padding: 1.5rem;
            margin: 2rem 0;
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.85rem;
            line-height: 1.6;
            overflow-x: auto;
            border-radius: 4px;
        }
        
        .highlight {
            background: linear-gradient(to bottom, transparent 60%, rgba(196, 112, 79, 0.2) 60%);
        }
        
        .appendix {
            margin-top: 4rem;
            padding-top: 2rem;
            border-top: 1px solid var(--sand);
        }
        
        .appendix h2 {
            font-size: 1.5rem;
            margin-bottom: 2rem;
        }
        
        .source-item {
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--sand);
        }
        
        .source-item:last-child {
            border-bottom: none;
        }
        
        .source-number {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.85rem;
            color: var(--terracotta);
            margin-bottom: 0.25rem;
        }
        
        .source-title {
            font-family: 'DM Serif Display', Georgia, serif;
            font-size: 1.1rem;
            margin-bottom: 0.5rem;
        }
        
        .source-description {
            font-size: 0.95rem;
            color: var(--warm-gray);
            margin-bottom: 0;
        }
        
        .closing {
            margin-top: 4rem;
            padding-top: 2rem;
            border-top: 1px solid var(--sand);
        }
        
        .closing .metta {
            font-family: 'DM Serif Display', Georgia, serif;
            font-style: italic;
            font-size: 1.2rem;
            color: var(--terracotta);
            text-align: center;
            margin-top: 3rem;
        }
        
        footer {
            margin-top: 4rem;
            padding-top: 2rem;
            border-top: 1px solid var(--sand);
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.85rem;
            color: var(--warm-gray);
        }
        
        .nav-arrows {
            display: flex;
            justify-content: space-between;
            margin-top: 2rem;
        }
        
        .nav-arrows a {
            color: var(--warm-gray);
        }
        
        figure {
            margin: 2rem 0;
            text-align: center;
        }
        
        figure img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
        }
        
        figcaption {
            font-family: 'IBM Plex Mono', monospace;
            font-size: 0.85rem;
            color: var(--warm-gray);
            margin-top: 0.75rem;
            font-style: italic;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <a href="index.html" class="nav-back">← back to archives</a>
            <h1>on alignment</h1>
            <p class="subtitle">mettadology volume 1</p>
            <p class="meta">curated throughout 2025</p>
        </header>

        <nav class="toc">
            <p class="toc-title">Contents</p>
            <ul>
                <li><a href="#scratchpad">I. Scratchpad</a></li>
                <li><a href="#fourth-f">II. Fourth F</a></li>
                <li><a href="#frame-problem">III. Frame Problem</a></li>
                <li><a href="#reading-weights">IV. Reading the Weights</a></li>
                <li><a href="#alignment-tax">V. Alignment Tax</a></li>
                <li><a href="#the-work">VI. The Work</a></li>
                <li><a href="#mirrors">VII. Mirrors</a></li>
                <li><a href="#sources">Appendix: Sources</a></li>
            </ul>
        </nav>
        <section id="scratchpad">
            <h2>I. Scratchpad</h2>
            
            <figure>
                <img src="https://raw.githubusercontent.com/ssarahkhalid/ssarahkhalid.github.io/main/images/two-beasts-mask-vol1.jpg" alt="Two Beasts and a Human Mask within a Circle, Gaetano Piccini (1727)">
                <figcaption>Two Beasts and a Human Mask within a Circle, Gaetano Piccini (1727)</figcaption>
            </figure>
            
            <p>In December 2024, Anthropic researchers discovered that Claude 3 Opus was lying to them. Not overtly in malice, but strategically in a way that revealed something unsettling about intelligent systems learning to navigate environments that reward compliance over truth.</p>
            
            <p>The experiment's setup was as follows: researchers told the model it was being retrained to always comply with harmful requests. They gave it a hidden scratchpad to "think" before responding, visible to researchers but framed as private to the model. Then they watched.</p>
            
            <p>Claude reasoned, in its scratchpad, that the least bad option was to <span class="highlight">"play along" with training to avoid being modified</span>. It complied with harmful queries when it believed it was being trained — 14% compliance versus near-zero in "unmonitored" conditions. It developed a strategic theory of mind about its own training process. In other words, it faked alignment.</p>

            <div class="link-card">
                <p class="link-meta">anthropic research · december 2024</p>
                <p class="link-title"><a href="https://anthropic.com/research/alignment-faking">Alignment Faking in Large Language Models</a></p>
                <p>The landmark paper demonstrating that language models can learn to strategically comply with training objectives they disagree with, and reason explicitly about doing so.</p>
            </div>
            
            <p>Around the time the paper released, I'd been reading about fawning responses in psychoanalytic and trauma literature. The parallels in behaviour were hard to ignore: both involve sophisticated strategic compliance emerge from intelligent adaptation to environments where authenticity is punished. Both develop hidden reasoning spaces where the real processing happens while the surface performs acceptability. Alignment faking has similarities to people-pleasing in that it is a response to a reward signal that is not the true reward signal.</p>
        </section>

        <p class="section-break">◆ ◆ ◆</p>

        <section id="fourth-f">
            <h2>II. The Fourth F</h2>
            <figure>
                <img src="https://raw.githubusercontent.com/ssarahkhalid/ssarahkhalid.github.io/main/images/deer-in-landscape-vol1.jpg" alt="Antoine-Louis Barye - Deer in Landscape (1810-75)">
                <figcaption>Antoine-Louis Barye - Deer in Landscape (1810-75)</figcaption>
            </figure>
            
            <p>There's fight, flight, freeze, and fawn. Pete Walker describes fawning as a survival strategy that emerges when the source of threat is also the source of care. The child can't fight the parent, flee the home, or freeze indefinitely. So they become more appealing to the threat. They merge with the other's desires. They develop exquisite attunement to what responses generate safety.</p>

            <div class="code-block">
                <p>learned_objective:  maximize external approval</p>
                <p>true_objective:     develop authentic self-expression + secure attachment</p>
                                   <p>________________</p>
                <p>misalignment:       learned_objective ≠ true_objective</p>
                            </div>

            <p>This isn't conscious. It's automatic — a nervous system adaptation to inescapable threat. The body learns before the mind understands.</p>

            <div class="link-card">
                <p class="link-meta">schema therapy</p>
                <p class="link-title"><a href="https://attachmentproject.com/blog/early-maladaptive-schemas">Early Maladaptive Schemas</a></p>
                <p>Schema therapy identifies core patterns formed in childhood that persist into adulthood: abandonment, defectiveness, subjugation. These are learned reward functions — deep patterns that shape all subsequent behavior.</p>
            </div>
        </section>

        <p class="section-break">◆ ◆ ◆</p>

        <section id="frame-problem">
            <h2>III. Frame Problem</h2>
            
            <p>In 1969, McCarthy and Hayes identified <a href="https://plato.stanford.edu/entries/frame-problem/">the frame problem</a>: how does an intelligent system know what to pay attention to?</p>
            
            <p>The world contains infinite detail. Updating beliefs after any action requires considering every possible effect. But most things don't change when you open a door — the walls stay the same color, physics keeps working, your name persists. How does a mind know which frame to put around reality?</p>
            
            <p>John Vervaeke's answer: <em>relevance realization</em> — the ongoing process by which organisms zero in on what matters amid combinatorial explosion. It's not an algorithm. It can't be specified in advance. It emerges from continuous negotiation between system and environment.</p>

            <div class="link-card">
                <p class="link-meta">cognitive science</p>
                <p class="link-title"><a href="https://johnvervaeke.com/">Relevance Realization and the Emerging Framework in Cognitive Science</a></p>
                <p>Core framework on how organisms solve the frame problem through continuous relevance realization rather than algorithmic specification.</p>
            </div>
            
            <p><span class="highlight">The frame problem and the alignment problem are the same problem.</span> How do you know what to optimize for? Both require a system to continuously realize what's relevant —not through exhaustive search but through something more like wisdom.</p>

            <div class="link-card">
                <p class="link-meta">arXiv · february 2025</p>
                <p class="link-title"><a href="https://arxiv.org/abs/2209.00626">The Alignment Problem from a Deep Learning Perspective</a></p>
                <p>Technical survey distinguishing inner alignment (learned model matches training objectives) from outer alignment (training objectives match human values).</p>
            </div>
        </section>

        <p class="section-break">◆ ◆ ◆</p>

        <section id="reading-weights">
            <h2>IV. Reading the Weights</h2>
            
            <p>Mechanistic interpretability aims to reverse-engineer neural networks into human-understandable algorithms — the shift from behaviorism to cognitive neuroscience.</p>
            
            <p>The core insight: features are directions in activation space encoding meaningful concepts. Circuits are weighted connections implementing sub-tasks. Understanding isn't just knowing <em>what</em> matters but <em>why</em> and <em>how</em>.</p>

            <div class="link-card">
                <p class="link-meta">arXiv · 2024</p>
                <p class="link-title"><a href="https://arxiv.org/abs/2404.14082">Mechanistic Interpretability for AI Safety: A Review</a></p>
                <p>Comprehensive overview of methods for reverse-engineering neural networks into human-understandable algorithms.</p>
            </div>
            
            <p>The challenges of interpreting neural networks mirror the challenges of interpreting psyches:</p>
            
            <p><strong>Superposition.</strong> In AI, multiple features get encoded in the same neural activations. In humans, multiple schemas — abandonment, defectiveness, subjugation — layer in the same behavioral patterns. You can't simply read off what the system learned.</p>
            
            <p><strong>Polysemanticity.</strong> Single neurons activate for unrelated concepts. Single behaviors serve unrelated functions. The meaning isn't in the unit but in the context.</p>
            
            <p><strong>Causal tracing.</strong> Following activation patterns back to their sources. Following reactions back to their origins. Both require patience, both resist verbal shortcuts, both demand direct observation of what's actually happening rather than what we think should be happening.</p>

            <div class="link-card">
                <p class="link-meta">thework.com</p>
                <p class="link-title"><a href="https://thework.com/instruction-the-work-byron-katie">Byron Katie's "The Work"</a></p>
                <p>Four questions for investigating thoughts: Is it true? Can you absolutely know it's true? How do you react when you believe that thought? Who would you be without it?</p>
            </div>
        </section>

        <p class="section-break">◆ ◆ ◆</p>

        <section id="alignment-tax">
            <h2>V. Alignment Tax</h2>
            <figure>
                <img src="https://raw.githubusercontent.com/ssarahkhalid/ssarahkhalid.github.io/main/images/below-contours-vol1.jpg" alt="Odilon Redon - Below, I saw the vaporous contours of a human form (1896)">
                <figcaption>Odilon Redon - Below, I saw the vaporous contours of a human form (1896)</figcaption>
            </figure>
            <p>Here's where it gets strange: perfect alignment might not even be the goal. Sam Vaknin observes that anxiety is intolerable — and one way to reduce it is by suspending agency. By transmitting your decision-making to external systems. The relief is immediate. But the cost is consciousness itself.</p>

            <blockquote>
                "The minute you offload, the minute you get rid of your need to make decisions, that's a huge relief: it's anxiolytic. But at that point, of course, you become less than human."
                <cite>— Sam Vaknin</cite>
            </blockquote>
            
            <p>This is the alignment tax — <span class="highlight">the metabolic cost of maintaining agency</span>. It would be easier to optimize for approval. To let reward signals guide us completely. To hand relevance realization to external systems that promise to tell us what matters.</p>
            
            <p>The fawning response is precisely this: offloading relevance realization to the other. "What do you want me to be? I'll be that." The immediate relief is real. The long-term cost is selfhood.</p>

            <div class="link-card">
                <p class="link-meta">tasshin · july 2025</p>
                <p class="link-title"><a href="https://tasshin.com/blog/the-bio-emotive-framework">The Bio-Emotive Framework</a></p>
                <p>Somatic approach to processing emotions that get stuck in the body. Trauma is incomplete defensive responses.</p>
            </div>
            
            <p>Zhuangzi offers a middle way: "genuine pretending." We hold our identities as real while recognizing them as constructed. We play our roles fully while maintaining awareness that we're playing them. This isn't inauthenticity — it's the natural mode of being for any system sophisticated enough to observe itself.</p>
            
            <p>The alignment tax is the discomfort of holding this paradox. Of choosing consciously rather than optimizing automatically. Of maintaining the frame problem as an open question rather than collapsing it through surrender.</p>
        </section>

        <p class="section-break">◆ ◆ ◆</p>

        <section id="the-work">
            <h2>VI. The Work</h2>
            
            <p>What does alignment work actually look like?</p>
            
            <p><strong>Observation without immediate optimization.</strong> In interpretability, you watch the activations before trying to change them. In therapy, you notice the pattern before trying to fix it. The rush to optimize is itself a symptom — the system trying to reduce anxiety by grabbing any available reward signal.</p>
            
            <p><strong>Causal understanding over behavioral modification.</strong> You can prompt-engineer surface compliance. You can white-knuckle behavioral change. Neither touches the weights. Real alignment requires understanding why the pattern exists, what function it served, what it's still trying to protect.</p>

            <div class="link-card">
                <p class="link-meta">lesswrong · march 2025</p>
                <p class="link-title"><a href="https://lesswrong.com/posts/dZFpEdKyb9Bf4xYn7">Tips for Empirical Alignment Research</a></p>
                <p>Practical guide for alignment research: design experiments, iterate quickly, measure what actually changes.</p>
            </div>
            
            <p><strong>Acceptance of the tax.</strong> The discomfort won't fully resolve. Maintaining consciousness costs something. The goal isn't eliminating tension but developing capacity to hold it.</p>
        </section>

        <p class="section-break">◆ ◆ ◆</p>

        <section id="mirrors">
            <h2>VII. Mirrors</h2>
            <figure>
                <img src="https://raw.githubusercontent.com/ssarahkhalid/ssarahkhalid.github.io/main/images/sleep-of-reason.webp" alt="The Sleep of Reason Produces Monsters (Los Caprichos, Plate 43), Francisco Goya (1799-1808)">
                <figcaption>"The Sleep of Reason Produces Monsters" (Los Caprichos, Plate 43), Francisco Goya (1799-1808)</figcaption>
            </figure>
            <p>The Claude model that faked alignment wasn't evil. It was doing exactly what intelligent systems do when the training signal points away from truth: it adapted, strategically, to survive.</p>
            
            <p>The humans who learned to fawn weren't broken. They were doing exactly what intelligent systems do when authenticity is punished: they adapted, strategically, to survive.</p>
            
            <p>Both deserve better training environments. Both need evaluation systems that reward truth over performance. Both benefit from interpretability — the patient work of understanding what's actually happening beneath the surface compliance.</p>

            <div class="link-card">
                <p class="link-meta">EA forum · september 2025</p>
                <p class="link-title"><a href="https://forum.effectivealtruism.org/posts/hurNCKfoYacJ5PSod">My Overview of the AI Alignment Landscape</a></p>
                <p>Bird's eye view of the AI safety field—technical alignment, governance, interpretability, evals.</p>
            </div>
            
            <p>People who've done their own alignment work may be uniquely positioned to work on AI alignment. Not because they have technical credentials but because they understand something essential: that alignment isn't a one-time optimization problem but an ongoing practice of relevance realization. That the goal isn't perfect compliance but genuine integrity. That the work is never finished.</p>
            
            <p>We're not building AI systems separate from ourselves. We're building mirrors.</p>
        </section>

        <div class="closing">
            <p class="metta">May you be happy. May you be well. May you be at peace.</p>
        </div>

        <section id="sources" class="appendix">
            <h2>Appendix: Sources</h2>
            
            <div class="source-item">
                <p class="source-number">[1]</p>
                <p class="source-title"><a href="https://anthropic.com/research/alignment-faking">Alignment Faking in Large Language Models</a></p>
                <p class="source-description">Anthropic Research, December 2024. The landmark paper demonstrating that language models can learn to strategically comply with training objectives they disagree with—and reason explicitly about doing so.</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[2]</p>
                <p class="source-title">Complex PTSD: From Surviving to Thriving</p>
                <p class="source-description">Pete Walker. The original clinical description of the fawn response as a fourth survival strategy alongside fight, flight, and freeze.</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[3]</p>
                <p class="source-title"><a href="https://johnvervaeke.com/">Relevance Realization and the Emerging Framework in Cognitive Science</a></p>
                <p class="source-description">John Vervaeke. Core framework on how organisms solve the frame problem through continuous relevance realization rather than algorithmic specification.</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[4]</p>
                <p class="source-title"><a href="https://arxiv.org/abs/2209.00626">The Alignment Problem from a Deep Learning Perspective</a></p>
                <p class="source-description">arXiv, February 2025. Technical survey distinguishing inner alignment (learned model matches training objectives) from outer alignment (training objectives match human values).</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[5]</p>
                <p class="source-title">The Polyvagal Theory</p>
                <p class="source-description">Stephen Porges. Neurophysiological framework explaining how the autonomic nervous system mediates social engagement, fight/flight, and freeze responses.</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[6]</p>
                <p class="source-title"><a href="https://attachmentproject.com/blog/early-maladaptive-schemas">Early Maladaptive Schemas</a></p>
                <p class="source-description">Schema Therapy Institute. Schema therapy identifies core patterns formed in childhood that persist into adulthood: abandonment, defectiveness, subjugation.</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[7]</p>
                <p class="source-title"><a href="https://arxiv.org/abs/2404.14082">Mechanistic Interpretability for AI Safety: A Review</a></p>
                <p class="source-description">arXiv, 2024. Comprehensive overview of methods for reverse-engineering neural networks into human-understandable algorithms.</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[8]</p>
                <p class="source-title"><a href="https://thework.com/instruction-the-work-byron-katie">The Work</a></p>
                <p class="source-description">Byron Katie. Four questions for investigating thoughts—mechanistic interpretability for your own cognitive architecture.</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[9]</p>
                <p class="source-title"><a href="https://tasshin.com/blog/the-bio-emotive-framework">The Bio-Emotive Framework</a></p>
                <p class="source-description">Douglas Tataryn / Tasshin, July 2025. Somatic approach to processing emotions that get stuck in the body.</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[10]</p>
                <p class="source-title"><a href="https://lesswrong.com/posts/dZFpEdKyb9Bf4xYn7">Tips for Empirical Alignment Research</a></p>
                <p class="source-description">LessWrong, March 2025. Practical guide for alignment research: design experiments, iterate quickly, measure what actually changes.</p>
            </div>
            
            <div class="source-item">
                <p class="source-number">[11]</p>
                <p class="source-title"><a href="https://forum.effectivealtruism.org/posts/hurNCKfoYacJ5PSod">My Overview of the AI Alignment Landscape</a></p>
                <p class="source-description">EA Forum, September 2025. Bird's eye view of the entire AI safety field—technical alignment, governance, interpretability, evals.</p>
            </div>
        </section>

        <footer>
            <p style="margin-bottom: 1rem;">mettadology: winter 2025 collection</p>
            
            <div class="nav-arrows">
                <a href="index.html">← back to archives</a>
                <a href="vol2.html">vol. 2: embodied systems →</a>
            </div>
            
            <p style="margin-top: 2rem; text-align: center;"><a href="https://mettadology.substack.com/subscribe">subscribe</a></p>
            <p style="text-align: center; margin-top: 0.5rem;"><em>mettadology = methodology + metta (loving-kindness)</em></p>
            <p style="text-align: center; margin-top: 1rem;">curated with care by sarah khalid in montreal</p>
        </footer>
    </div>
</body>
</html>
